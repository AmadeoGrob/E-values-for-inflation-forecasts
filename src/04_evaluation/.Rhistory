message(sprintf("-> Generating Panel C%d for %s (h=%d)...", i, cfg$model, cfg$horizon))
single_model_data <- region_calibration_all %>%
filter(model == cfg$model, horizon == cfg$horizon)
new_panel <- panel_c_pit_evolution(
cal_data    = single_model_data,
split_dates = cfg$split_dates,
model_name  = cfg$model,
horizon     = cfg$horizon,
panel_index = i
)
new_panel <- new_panel & theme(
plot.margin = margin(t = 0.5, r = 1, b = 0.5, l = 1,),
)
if (is.null(extracted_legend_long)) {
extracted_legend_long <- ggpubr::get_legend(new_panel)
}
panel_c_list_long <- c(panel_c_list_long, list(new_panel + theme(legend.position = "none")))
}
}
# Combine if any panels were created
if (length(panel_c_list_long) > 0) {
final_plot <- p_long
for (p_c in panel_c_list_long) {
final_plot <- final_plot / p_c
}
num_panel_c <- length(panel_c_list_long)
layout_heights <- c(2, rep(1, num_panel_c), 0.1)
p_long <- final_plot / extracted_legend_long + plot_layout(heights = layout_heights)
pdf_height <- 4 + 2 * num_panel_c + 0.25
} else {
p_long <- p_long
pdf_height <- 4
}
print(p_long)
# Long horizons
if (SAVE_PLOTS) {
fn <- sprintf("%s_%s_horizons_long_calibration.pdf", tolower(region), tolower(g))
pdf_path <- file.path(out_dir, fn)
pdf_width  <- 8
grDevices::cairo_pdf(filename = pdf_path, width = pdf_width, height = pdf_height, family = "LMRoman")
print(p_long)
grDevices::dev.off()
}
}
} # End of group loop
} # End of region loop
# ---- 3. (Optional) Convenience: combine to single data frames you can save ----
# ready-to-save tibbles across regions/horizons:
KS_RESULTS_ALL <- dplyr::bind_rows(
setNames(lapply(KS_STORE, function(x) dplyr::bind_rows(x, .id = "horizon")), names(KS_STORE)),
.id = "region"
) %>% dplyr::mutate(horizon = as.integer(horizon))
BOUNDARY_RESULTS_ALL <- dplyr::bind_rows(
setNames(lapply(BOUNDARY_STORE, function(x) dplyr::bind_rows(x, .id = "horizon")), names(BOUNDARY_STORE)),
.id = "region"
) %>% dplyr::mutate(horizon = as.integer(horizon))
CROSSING_RESULTS_ALL <- dplyr::bind_rows(
setNames(lapply(CROSSING_STORE, function(x) dplyr::bind_rows(x, .id = "horizon")), names(CROSSING_STORE)),
.id = "region"
) %>% dplyr::mutate(horizon = as.integer(horizon))
# Saves:
readr::write_csv(KS_RESULTS_ALL,       file.path(TABLE_DIR, "ks_results_all.csv"))
readr::write_csv(BOUNDARY_RESULTS_ALL, file.path(TABLE_DIR, "boundary_summary_all.csv"))
readr::write_csv(CROSSING_RESULTS_ALL, file.path(TABLE_DIR, "e_crossing_all.csv"))
# ---- 4. Region-specific LaTeX calibration tables ----------------------------
# Requires: KS_RESULTS_ALL, BOUNDARY_RESULTS_ALL, CROSSING_RESULTS_ALL
# Define which pairs you want per page
# Switzerland
write_combined_region_table(
region_key = "ch",
label      = "tab:ch_calibration_summary",
caption    = "Calibration diagnostics for Switzerland across horizons."
)
# Euro Area
write_combined_region_table(
region_key = "eu",
label      = "tab:eu_calibration_summary",
caption    = "Calibration diagnostics for the Euro Area across horizons."
)
# United States
write_combined_region_table(
region_key = "us",
label      = "tab:us_calibration_summary",
caption    = "Calibration diagnostics for the United States across horizons."
)
# =============================================================================
#
# Main Analysis: Sequential Calibration of Inflation Forecasts
#
# Description:
# This script orchestrates the full analysis workflow for the thesis. It iterates
# through different geographic regions (CH, EU, US) and forecast horizons,
# loading the corresponding forecast data for various models (Baselines, BVARs,
# DFM, DRF).
#
# For each model, it computes:
#   1. Calibration diagnostics (PITs or ranks).
#   2. Sequential e-processes for testing calibration over time.
#
# The script then generates and saves summary tables and diagnostic plots that
# form the core results of the analysis.
#
# =============================================================================
# ---- 0. Setup: Load Libraries and Helper Functions --------------------------
# --- Load required packages ---
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(fs)
library(epit)
library(patchwork)
library(lubridate)
library(KernSmooth)
library(bde)
library(sysfonts)
library(showtext)
library(MASS)
# --- Load project-specific helpers and set theme ---
source("calibration_helpers.R")
source("font_theme_helpers.R")
init_lmodern_theme()  # uses LM Roman + theme_bw(base_size = 10)
showtext::showtext_opts(dpi = 96)
# ---- 1. Configuration: Define Analysis Parameters ---------------------------
# --- Core analysis dimensions ---
HORIZONS <- c(1L, 2L, 3L, 6L, 12L)
REGIONS  <- c("ch", "eu", "us")
GROUPS   <- c("Baseline", "BVAR", "Advanced")
# --- File path configuration ---
# Assumes the script is run from a directory where `here()` points to the project root.
RESULTS_DIR <- here("..", "..", "results")
# Directories for different forecast model outputs
BVAR_DIR    <- file.path(RESULTS_DIR, "forecasts", "bvar")
BASELINE_DIR <- file.path(RESULTS_DIR, "forecasts", "baseline")
DRF_DIR      <- file.path(RESULTS_DIR, "forecasts", "drf")
DFM_DIR      <- file.path(RESULTS_DIR, "forecasts", "dfm")
# Directories for saving outputs
PLOT_DIR   <- file.path(RESULTS_DIR, "plots")
TABLE_DIR  <- file.path(RESULTS_DIR, "tables")
# --- Analysis parameters ---
WARMUP_N0 <- 10L # Fixed n0 for all e-value calculations
# Define the intended start dates for the out-of-sample evaluation window
EVAL_WINDOW <- list(
ch = list(start = as.Date("1999-12-01"), end = NULL),
eu = list(start = as.Date("2010-09-01"), end = NULL),
us = list(start = as.Date("1986-02-01"), end = NULL)
)
# --- Control flags ---
SAVE_PLOTS <- TRUE
# ---- Collectors for printed summaries (per region -> per horizon) ----
KS_STORE        <- list()
BOUNDARY_STORE  <- list()
CROSSING_STORE  <- list()
# --- Configuration for selective "Panel C" PIT evolution plots ---
# Use the 'pretty' model name as it appears on the plots.
PANEL_C_CONFIG <- list(
# Analyze DRF model for Switzerland at h=1
list(
region      = "ch",
model       = "DRF",
horizon     = 1,
split_dates = as.Date(c("1999-12-1", "2009-12-01", "2017-01-01", "2018-06-01", "2021-01-01"))
),
# Analyze DFM model for US at h=1
list(
region      = "us",
model       = "DFM",
horizon     = 1,
split_dates = as.Date(c("1986-02-01","1999-01-01", "2007-01-01", "2010-06-01"))
),
# Analyze DFM model for US at h=2
list(
region      = "us",
model       = "DFM",
horizon     = 2,
split_dates = as.Date(c("1986-02-01", "2007-06-01", "2010-06-01", "2020-01-01"))
),
# Analyze DFM model for EA at h=1
list(
region      = "eu",
model       = "DFM",
horizon     = 1,
split_dates = as.Date(c("2010-09-01", "2022-01-01", "2023-12-01"))
),
# Analyze DRF model for EA at h=1
list(
region      = "eu",
model       = "DRF",
horizon     = 1,
split_dates = as.Date(c("2010-09-01", "2013-01-01", "2016-06-01", "2020-01-01"))
)
)
# ---- 2. Run Main Analysis Loop --------------------------------------------
# Iterate over each region
for (region in REGIONS) {
message(sprintf("\n\n===================="))
message(sprintf("Processing Region: %s", toupper(region)))
message(sprintf("===================="))
# init sublists for this region
KS_STORE[[region]]       <- list()
BOUNDARY_STORE[[region]] <- list()
CROSSING_STORE[[region]] <- list()
# Lists to aggregate data from all horizons for the current region
all_pieces_for_region <- list()
# Iterate over each forecast horizon
for (h in HORIZONS) {
message(sprintf("\n=== Processing Horizon h=%d for %s ===", h, toupper(region)))
# --- Step 2.1: Load and Prepare Data for the Current Horizon ---
# Set the evaluation window start/end dates (mainly use for start)
win <- EVAL_WINDOW[[region]]
user_start <- if (is.null(win$start)) NULL else as.Date(win$start)
user_end   <- if (is.null(win$end))   NULL else as.Date(win$end)
# Find all relevant forecast files for the current region
pat <- sprintf("^.*/%s_.*\\.csv$", region)
files <- c(fs::dir_ls(BVAR_DIR, regexp=pat), fs::dir_ls(BASELINE_DIR, regexp=pat),
fs::dir_ls(DFM_DIR, regexp=pat))
# Load all CSV-based models into a named list
csv_models <- setNames(lapply(files, function(p) read_csv(p, show_col_types=FALSE)),
basename(files))
# Load DRF model results separately (different structure)
drf_results_path <- file.path(DRF_DIR, sprintf("%s_drf_forecast_results.csv", region))
drf_results <- if (file.exists(drf_results_path)) read_csv(drf_results_path,
show_col_types=FALSE)
else NULL
# --- Determine the effective start date for the evaluation ---
# The effective start date is the LATEST date at which ALL models have valid forecasts.
# We take the maximum of the user-defined start date and the auto-detected date.
starts <- c()
for (nm in names(csv_models)) {
grp <- detect_group(nm)
if (grp != "Baseline") starts <- c(starts, usable_start_gaussian(csv_models[[nm]], h))
}
if (!is.null(drf_results)) {
drf_res_h <- drf_results[drf_results$horizon_step == h, , drop=FALSE]
if (nrow(drf_res_h) > 0) starts <- c(starts, min(as.Date(drf_res_h$target_time),
na.rm=TRUE))
}
eval_start_auto <- suppressWarnings(max(starts, na.rm=TRUE))
if (is.infinite(eval_start_auto)) eval_start_auto <- NA_Date_
else if (!inherits(eval_start_auto, "Date")) eval_start_auto <- as.Date(eval_start_auto)
eval_start_effective <- if (!is.null(user_start)) user_start else eval_start_auto
# --- Step 2.2: Compute Calibration Series for Each Model ---
pieces_h <- list()
# Process all CSV-based models
for (nm in names(csv_models)) {
pieces_h[[nm]] <- tryCatch(
compute_model_series(nm, df=csv_models[[nm]], type="auto", horizon=h, n0=WARMUP_N0,
start_date=eval_start_effective, end_date=user_end),
error = function(e) { message("Skip ", nm, ": ", e$message); NULL }
)
}
# Process the DRF model
if (!is.null(drf_results)) {
drf_dists_path <- file.path(DRF_DIR, sprintf("%s_h%d_distributions.rds", region, h))
if (file.exists(drf_dists_path)) {
drf_dists <- readRDS(drf_dists_path)
pieces_h[["drf"]] <- compute_model_series("drf", type="drf", horizon=h, drf_results=drf_results,
drf_dists=drf_dists, n0=WARMUP_N0,
start_date=eval_start_effective,
end_date=user_end)
}
}
pieces_h <- Filter(Negate(is.null), pieces_h)
if (!length(pieces_h)) { message("No models found for ", region, " at h=", h); next
}
# --- Step 2.3: Summarize and Print Horizon-Specific Results ---
cal_h <- bind_rows(lapply(pieces_h, `[[`, "calibration_data"))
e_h   <- bind_rows(lapply(pieces_h, `[[`, "e"))
# - Static KS Test Results -
ks_results <- calculate_ks_test(cal_h %>% filter(type == "pit"))
# store
KS_STORE[[region]][[as.character(h)]] <-
ks_results %>% dplyr::mutate(region = toupper(region), horizon = h)
# - Boundary Value Analysis (PITs at 0 or 1) -
boundary_list <- lapply(names(pieces_h), function(model_name) {
stats <- pieces_h[[model_name]]$boundary_stats
stats$model <- pretty_model(model_name)
return(stats)
})
boundary_summary <- bind_rows(boundary_list) %>% dplyr::select(model, boundary_count,
total_observations, boundary_share) %>% arrange(model)
# store
BOUNDARY_STORE[[region]][[as.character(h)]] <-
boundary_summary %>% dplyr::mutate(region = toupper(region), horizon = h)
# - E-Value Crossing Dates, max and terminal value-
suppressWarnings({
crossing_dates_ext <- e_h %>%
dplyr::arrange(target_time) %>%
dplyr::group_by(model, method, horizon) %>%
dplyr::summarise(
first_cross_10  = min(target_time[e > 10],  na.rm = TRUE),
first_cross_100 = min(target_time[e > 100], na.rm = TRUE),
e_max  = max(e, na.rm = TRUE),
e_last = {
ee <- e[is.finite(e)]
if (length(ee)) dplyr::last(ee) else NA_real_
},
.groups = "drop"
) %>%
dplyr::mutate(
first_cross_10  = dplyr::if_else(is.infinite(first_cross_10),  as.Date(NA), first_cross_10),
first_cross_100 = dplyr::if_else(is.infinite(first_cross_100), as.Date(NA), first_cross_100)
) %>%
dplyr::arrange(model, method)
})
# store
CROSSING_STORE[[region]][[as.character(h)]] <-
crossing_dates_ext %>% dplyr::mutate(region = toupper(region))
# --- Step 2.4: Aggregate results for this region's plots ---
all_pieces_for_region <- c(all_pieces_for_region, pieces_h)
} # --- End of horizon loop ---
# --- Step 2.5: Create and Save Consolidated Plots for the Region ---
if (!length(all_pieces_for_region)) next
# Combine data from all horizons for the current region
region_calibration_all <- bind_rows(lapply(all_pieces_for_region, `[[`, "calibration_data"))
region_e_all <- bind_rows(lapply(all_pieces_for_region, `[[`, "e"))
# Create a separate plot for each model group
for (g in GROUPS) {
message(sprintf("\n--- Generating consolidated plots for Group: %s ---", g))
cal_g <- region_calibration_all %>% dplyr::filter(group == g)
e_g   <- region_e_all %>% dplyr::filter(group == g)
if (nrow(cal_g) == 0 && nrow(e_g) == 0) next
# --- Plot 1: Short Horizons (h = 1, 2,) ---
cal_short <- cal_g %>% filter(horizon %in% c(1, 2))
e_short   <- e_g   %>% filter(horizon %in% c(1, 2))
if(nrow(e_short) > 0) {
p_top <- if (nrow(cal_short) > 0) panel_a(cal_short, region_label = region,
add_density = FALSE) else patchwork::plot_spacer()
p_top <- p_top & theme(plot.margin = margin(0.5, 1, 0.5, 0.5))
p_mid <- panel_b(e_short, region_label = region) &
theme(plot.margin = margin(0.5, 0.5, 0.5, 1))
# Combine panels side-by-side
p_short <- (p_top + p_mid + plot_layout(widths = c(1, 1)))
# --- Check for and append multiple Panel Cs ---
plot_models_short <- unique(cal_short$model)
panel_c_list <- list()
# First, find all matching configurations for this plot
short_matches <- purrr::keep(PANEL_C_CONFIG, ~.$region == region &
.$model %in% plot_models_short &
.$horizon %in% c(1, 2))
if (length(short_matches) > 0) {
extracted_legend <- NULL
# Now loop through only the matches
for (i in seq_along(short_matches)) {
cfg <- short_matches[[i]]
message(sprintf("-> Generating Panel C%d for %s (h=%d)...", i, cfg$model, cfg$horizon))
single_model_data <- region_calibration_all %>%
filter(model == cfg$model, horizon == cfg$horizon)
new_panel <- panel_c_pit_evolution(
cal_data    = single_model_data,
split_dates = cfg$split_dates,
model_name  = cfg$model,
horizon     = cfg$horizon,
panel_index = i
)
new_panel <- new_panel & theme(
plot.margin = margin(t = 0.5, r = 1, b = 0.5, l = 1,),
)
if (is.null(extracted_legend)) {
extracted_legend <- ggpubr::get_legend(new_panel)
}
panel_c_list <- c(panel_c_list, list(new_panel + theme(legend.position = "none")))
}
}
# Combine if any panels were created
if (length(panel_c_list) > 0) {
# Stack all the legend-less plots
final_plot_stack <- p_short
for (p_c in panel_c_list) {
final_plot_stack <- final_plot_stack / p_c
}
# Define heights for the plot stack
num_panel_c <- length(panel_c_list)
plot_heights <- c(2, rep(1, num_panel_c), 0.1)
# Add the single legend to the bottom of the entire arrangement
p_short <- final_plot_stack / extracted_legend + plot_layout(heights = plot_heights)
pdf_height <- 4 + 2 * num_panel_c + 0.25
} else {
p_short <- p_short
pdf_height <- 4
}
print(p_short)
# Short horizons
if (SAVE_PLOTS) {
out_dir <- file.path(PLOT_DIR, toupper(region)); fs::dir_create(out_dir)
fn <- sprintf("%s_%s_horizons_short_calibration.pdf", tolower(region), tolower(g))
pdf_path <- file.path(out_dir, fn)
# choose the final page width (fixed)
pdf_width  <- 8
grDevices::cairo_pdf(filename = pdf_path, width = pdf_width, height = pdf_height, family = "LMRoman")
print(p_short)
grDevices::dev.off()
}
}
# --- Plot 2: Long Horizons (h = 3, 6, 12) ---
cal_long <- cal_g %>% filter(horizon %in% c(3, 6, 12))
e_long   <- e_g   %>% filter(horizon %in% c(3, 6, 12))
if(nrow(e_long) > 0) {
p_top <- if (nrow(cal_long) > 0) panel_a(cal_long, region_label = region,
add_density = FALSE) else patchwork::plot_spacer()
p_top <- p_top & theme(plot.margin = margin(0.5, 1, 0.5, 0.5))
p_mid <- panel_b(e_long, region_label = region) &
theme(plot.margin = margin(0.5, 0.5, 0.5, 1))
# For side-by-side layout and adjust `widths`
p_long <- (p_top + p_mid + plot_layout(widths = c(1, 1)))
# --- Check for and append multiple Panel Cs ---
plot_models_long <- unique(cal_long$model)
panel_c_list_long <- list()
# First, find all matching configurations for this plot
long_matches <- purrr::keep(PANEL_C_CONFIG, ~.$region == region &
.$model %in% plot_models_long &
.$horizon %in% c(3, 6, 12))
if (length(long_matches) > 0) {
extracted_legend_long <- NULL
# Now loop through only the matches
for (i in seq_along(long_matches)) {
cfg <- long_matches[[i]]
message(sprintf("-> Generating Panel C%d for %s (h=%d)...", i, cfg$model, cfg$horizon))
single_model_data <- region_calibration_all %>%
filter(model == cfg$model, horizon == cfg$horizon)
new_panel <- panel_c_pit_evolution(
cal_data    = single_model_data,
split_dates = cfg$split_dates,
model_name  = cfg$model,
horizon     = cfg$horizon,
panel_index = i
)
new_panel <- new_panel & theme(
plot.margin = margin(t = 0.5, r = 1, b = 0.5, l = 1,),
)
if (is.null(extracted_legend_long)) {
extracted_legend_long <- ggpubr::get_legend(new_panel)
}
panel_c_list_long <- c(panel_c_list_long, list(new_panel + theme(legend.position = "none")))
}
}
# Combine if any panels were created
if (length(panel_c_list_long) > 0) {
final_plot <- p_long
for (p_c in panel_c_list_long) {
final_plot <- final_plot / p_c
}
num_panel_c <- length(panel_c_list_long)
layout_heights <- c(2, rep(1, num_panel_c), 0.1)
p_long <- final_plot / extracted_legend_long + plot_layout(heights = layout_heights)
pdf_height <- 4 + 2 * num_panel_c + 0.25
} else {
p_long <- p_long
pdf_height <- 4
}
print(p_long)
# Long horizons
if (SAVE_PLOTS) {
fn <- sprintf("%s_%s_horizons_long_calibration.pdf", tolower(region), tolower(g))
pdf_path <- file.path(out_dir, fn)
pdf_width  <- 8
grDevices::cairo_pdf(filename = pdf_path, width = pdf_width, height = pdf_height, family = "LMRoman")
print(p_long)
grDevices::dev.off()
}
}
} # End of group loop
} # End of region loop
# ---- 3. (Optional) Convenience: combine to single data frames you can save ----
# ready-to-save tibbles across regions/horizons:
KS_RESULTS_ALL <- dplyr::bind_rows(
setNames(lapply(KS_STORE, function(x) dplyr::bind_rows(x, .id = "horizon")), names(KS_STORE)),
.id = "region"
) %>% dplyr::mutate(horizon = as.integer(horizon))
BOUNDARY_RESULTS_ALL <- dplyr::bind_rows(
setNames(lapply(BOUNDARY_STORE, function(x) dplyr::bind_rows(x, .id = "horizon")), names(BOUNDARY_STORE)),
.id = "region"
) %>% dplyr::mutate(horizon = as.integer(horizon))
CROSSING_RESULTS_ALL <- dplyr::bind_rows(
setNames(lapply(CROSSING_STORE, function(x) dplyr::bind_rows(x, .id = "horizon")), names(CROSSING_STORE)),
.id = "region"
) %>% dplyr::mutate(horizon = as.integer(horizon))
# Saves:
readr::write_csv(KS_RESULTS_ALL,       file.path(TABLE_DIR, "ks_results_all.csv"))
readr::write_csv(BOUNDARY_RESULTS_ALL, file.path(TABLE_DIR, "boundary_summary_all.csv"))
readr::write_csv(CROSSING_RESULTS_ALL, file.path(TABLE_DIR, "e_crossing_all.csv"))
# ---- 4. Region-specific LaTeX calibration tables ----------------------------
# Requires: KS_RESULTS_ALL, BOUNDARY_RESULTS_ALL, CROSSING_RESULTS_ALL
# Define which pairs you want per page
# Switzerland
write_combined_region_table(
region_key = "ch",
label      = "tab:ch_calibration_summary",
caption    = "Calibration diagnostics for Switzerland across horizons.
The p-values are from a two-sided one sample KS test for uniformity of the PITs.
Edge frequency denotes the share of PIT values at the boundaries (0 or 1) during the whole
evaluation period. Max e is the maximally attained e-value during the evaluation period."
)
# Euro Area
write_combined_region_table(
region_key = "eu",
label      = "tab:eu_calibration_summary",
caption    = "Calibration diagnostics for the Euro Area across horizons.
The p-values are from a two-sided one sample KS test for uniformity of the PITs.
Edge frequency denotes the share of PIT values at the boundaries (0 or 1) during the whole
evaluation period. Max e is the maximally attained e-value during the evaluation period."
)
# United States
write_combined_region_table(
region_key = "us",
label      = "tab:us_calibration_summary",
caption    = "Calibration diagnostics for the United States across horizons.
The p-values are from a two-sided one sample KS test for uniformity of the PITs.
Edge frequency denotes the share of PIT values at the boundaries (0 or 1) during the whole
evaluation period. Max e is the maximally attained e-value during the evaluation period."
)
